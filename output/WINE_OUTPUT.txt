SIGMOID ACTIVATION FUNCTION WITH 10000 ITERATIONS AND LEARNING RATE OF 0.005

D:\UTD\CS 6375 Machine Learning\Assignments\Assignment-3>python NeuralNet.py https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data 10000 0.005 sigmoid
After 10000 iterations, the total error is 1.2928654791788285
The final weight vectors are (starting from input to output layers)
[[-0.44432925  0.05794698 -1.21124174 -3.69025999]
 [-0.36675336 -0.45314212  1.13545473  0.44553379]
 [-0.28629994 -0.02756575 -0.4718404  -1.24559636]
 [-0.38385641  0.10018492 -0.2210971   0.63779295]
 [ 0.12128657 -0.05743642 -0.16548284 -0.95150123]
 [-0.3063777  -1.08021581  0.03863601  1.68584188]
 [ 0.61416647  0.32439058  0.59044881  0.07203996]
 [ 0.74210454 -0.04232407 -0.50573837 -0.06145845]
 [-0.61965952 -0.87754018 -0.77999675 -1.46337005]
 [ 0.77809878 -0.24269799 -0.60621482  0.69362257]
 [-0.80300804 -1.07961205  1.34194009  0.59698812]
 [ 0.51319821  0.542917   -0.77374307  0.46424531]
 [ 0.64393459  0.01516956  0.2238608  -0.28198644]]
[[-0.7623834   0.8995487 ]
 [-0.96989184  1.80930809]
 [ 0.18685129 -0.55132749]
 [ 2.14255422 -2.50619871]]
[[ 3.03098839]
 [-3.14072319]]
Test Output error: 0.45103357428344

______________________________________________________________________________________________________________________________________________________________________

TANH ACTIVATION FUNCTION WITH 10000 ITERATIONS AND LEARNING RATE OF 0.005

D:\UTD\CS 6375 Machine Learning\Assignments\Assignment-3>python NeuralNet.py https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data 10000 0.005 tanh
After 10000 iterations, the total error is 0.7887520268772841
The final weight vectors are (starting from input to output layers)
[[-0.91909798 -0.57312339 -0.07599956 -0.46652403]
 [ 0.05253611 -0.81170113  0.50767675 -0.57827809]
 [-1.18687283 -0.18004958  1.10236458 -0.05022703]
 [-0.52985265  0.6181751   0.35031601  0.33371311]
 [-0.04754916 -0.86814028  0.08613462 -0.4088708 ]
 [-0.17203427  0.11142245 -1.24713127  1.29106825]
 [ 1.22425037  0.6567163   0.04977758 -0.45836464]
 [ 0.27582053 -1.12332362 -1.7678566  -0.21396149]
 [-0.5174713  -2.10327687  0.81946293 -0.55040264]
 [ 0.21886072  0.42309304 -0.27208002  0.5664694 ]
 [-0.41006877 -0.7473409   0.31170623  0.89209026]
 [ 0.58178849  0.28242331 -0.15222368 -0.13127988]
 [ 0.65587234  0.14888394 -0.30818853 -0.07908998]]
[[-1.87685517  0.29466994]
 [-0.20757476  0.86294355]
 [-0.42460783 -0.54156915]
 [ 1.03778564 -1.22597982]]
[[-1.12669572]
 [-1.69765322]]
Test Output error: 0.7381888435967234

______________________________________________________________________________________________________________________________________________________________________

RELU ACTIVATION FUNCTION WITH 10000 ITERATIONS AND LEARNING RATE OF 0.005

D:\UTD\CS 6375 Machine Learning\Assignments\Assignment-3>python NeuralNet.py https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data 10000 0.005 relu
After 10000 iterations, the total error is 21.824405672890528
The final weight vectors are (starting from input to output layers)
[[-0.20737342 -0.78526939  0.01962056 -0.79572953]
 [-0.42256433 -0.53648307  0.93533586 -0.44336232]
 [-0.53275495 -0.81688712  0.14013332 -0.16414692]
 [-0.26431352  0.62598994 -0.42047999  0.4347832 ]
 [ 0.22589619 -0.14618035  0.50374594 -0.14437473]
 [-0.14323519 -0.27619111 -0.69332304  0.87438065]
 [ 0.83281975  0.56391692  0.23265789 -0.92800113]
 [ 0.30864754 -0.74046078 -0.41128105 -0.27837049]
 [-0.4507097  -0.85206201 -0.69572568 -0.67676295]
 [ 0.8774234  -0.2577322  -0.89996383  0.48191111]
 [-0.40263952 -0.59128374  0.96351328  0.78604242]
 [ 0.51869759  0.30224112 -0.920633    0.62775273]
 [ 0.52514627 -0.08943507  0.0636529  -0.78132786]]
[[-0.70793451  0.01757748]
 [-0.56869944  0.83288741]
 [-0.07569497 -0.73546545]
 [ 0.52848322 -0.5745326 ]]
[[-0.85148313]
 [-0.8091615 ]]
Test Output error: 5.979188345473465
